{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from miscnn.data_loading.interfaces import NIFTI_interface, DICOM_interface\n",
    "from miscnn import Data_IO\n",
    "#from plotnine import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize prediction vs Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_evaluation(case_id, vol, truth, pred, eva_path):\n",
    "    # Squeeze image files to remove channel axis\n",
    "    vol = np.squeeze(vol, axis=-1)\n",
    "    truth = np.squeeze(truth, axis=-1)\n",
    "    pred = np.squeeze(pred, axis=-1)\n",
    "    # Color volumes according to truth and pred segmentation\n",
    "    vol_raw = overlay_segmentation(vol, np.zeros(vol.shape))\n",
    "    vol_truth = overlay_segmentation(vol, truth)\n",
    "    vol_pred = overlay_segmentation(vol, pred)\n",
    "    # Create a figure and two axes objects from matplot\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    # Initialize the two subplots (axes) with an empty image\n",
    "    data = np.zeros(vol.shape[0:2])\n",
    "    ax1.set_title(\"CT Scan\")\n",
    "    ax2.set_title(\"Ground Truth\")\n",
    "    ax3.set_title(\"Prediction\")\n",
    "    img1 = ax1.imshow(data)\n",
    "    img2 = ax2.imshow(data)\n",
    "    img3 = ax3.imshow(data)\n",
    "    # Update function for both images to show the slice for the current frame\n",
    "    def update(i):\n",
    "        if i < vol.shape[0]:\n",
    "            plt.suptitle(\"Case ID: \" + str(case_id) + \" - \" + \"Slice: \" + str(i))\n",
    "            img1.set_data(vol_raw[i, :, :])\n",
    "            img2.set_data(vol_truth[i, :, :])\n",
    "            img3.set_data(vol_pred[i, :, :])\n",
    "            return [img1, img2, img3]\n",
    "        else:\n",
    "            return []\n",
    "    # Compute the animation (gif)\n",
    "    ani = animation.FuncAnimation(fig, update, frames=vol.shape[0],\n",
    "                                  interval=10, repeat_delay=0, blit=False)\n",
    "    # Set up the output path for the gif\n",
    "    if not os.path.exists(eva_path):\n",
    "        os.mkdir(eva_path)\n",
    "    file_name = \"visualization.\" + str(case_id).zfill(5) + \".gif\"\n",
    "    out_path = os.path.join(eva_path, file_name)\n",
    "    # Save the animation (gif)\n",
    "    ani.save(out_path, writer='imagemagick', fps=20, dpi=150)\n",
    "    # Close the matplot\n",
    "    plt.close()\n",
    "\n",
    "# Based on: https://github.com/neheller/kits19/blob/master/starter_code/visualize.py\n",
    "def overlay_segmentation(vol, seg):\n",
    "    # Clip intensities to -1250 and +250\n",
    "    vol = np.clip(vol, -3000, 3500)\n",
    "    # Scale volume to greyscale range\n",
    "    vol_scaled = (vol - np.min(vol)) / (np.max(vol) - np.min(vol))\n",
    "    vol_greyscale = np.around(vol_scaled * 255, decimals=0).astype(np.uint8)\n",
    "    # Convert volume to RGB\n",
    "    vol_rgb = np.stack([vol_greyscale, vol_greyscale, vol_greyscale], axis=-1)\n",
    "    # Initialize segmentation in RGB\n",
    "    shp = seg.shape\n",
    "    seg_rgb = np.zeros((shp[0], shp[1], shp[2], 3), dtype=int)\n",
    "    # Set class to appropriate color\n",
    "    seg_rgb[np.equal(seg, 1)] = [0, 0, 255]\n",
    "    seg_rgb[np.equal(seg, 2)] = [0, 0, 255]\n",
    "    seg_rgb[np.equal(seg, 3)] = [255, 0, 0]\n",
    "    # Get binary array for places where an ROI lives\n",
    "    segbin = np.greater(seg, 0)\n",
    "    repeated_segbin = np.stack((segbin, segbin, segbin), axis=-1)\n",
    "    # Weighted sum where there's a value to overlay\n",
    "    alpha = 0.3\n",
    "    vol_overlayed = np.where(\n",
    "        repeated_segbin,\n",
    "        np.round(alpha*seg_rgb+(1-alpha)*vol_rgb).astype(np.uint8),\n",
    "        np.round(vol_rgb).astype(np.uint8)\n",
    "    )\n",
    "    # Return final volume with segmentation overlay\n",
    "    return vol_overlayed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------#\n",
    "#                  Score Calculations                 #\n",
    "#-----------------------------------------------------#\n",
    "def calc_DSC(truth, pred, classes):\n",
    "    dice_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            gt = np.equal(truth, i)\n",
    "            pd = np.equal(pred, i)\n",
    "            # Calculate Dice\n",
    "            dice = 2*np.logical_and(pd, gt).sum() / (pd.sum() + gt.sum())\n",
    "            dice_scores.append(dice)\n",
    "        except ZeroDivisionError:\n",
    "            dice_scores.append(0.0)\n",
    "    # Return computed Dice Similarity Coefficients\n",
    "    return dice_scores\n",
    "\n",
    "def calc_IoU(truth, pred, classes):\n",
    "    iou_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            gt = np.equal(truth, i)\n",
    "            pd = np.equal(pred, i)\n",
    "            # Calculate iou\n",
    "            iou = np.logical_and(pd, gt).sum() / (pd.sum() + gt.sum() - np.logical_and(pd, gt).sum())\n",
    "            iou_scores.append(iou)\n",
    "        except ZeroDivisionError:\n",
    "            iou_scores.append(0.0)\n",
    "    # Return computed IoU\n",
    "    return iou_scores\n",
    "\n",
    "def calc_Sensitivity(truth, pred, classes):\n",
    "    sens_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            gt = np.equal(truth, i)\n",
    "            pd = np.equal(pred, i)\n",
    "            # Calculate sensitivity\n",
    "            sens = np.logical_and(pd, gt).sum() / gt.sum()\n",
    "            sens_scores.append(sens)\n",
    "        except ZeroDivisionError:\n",
    "            sens_scores.append(0.0)\n",
    "    # Return computed sensitivity scores\n",
    "    return sens_scores\n",
    "\n",
    "def calc_Specificity(truth, pred, classes):\n",
    "    spec_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            not_gt = np.logical_not(np.equal(truth, i))\n",
    "            not_pd = np.logical_not(np.equal(pred, i))\n",
    "            # Calculate specificity\n",
    "            spec = np.logical_and(not_pd, not_gt).sum() / (not_gt).sum()\n",
    "            spec_scores.append(spec)\n",
    "        except ZeroDivisionError:\n",
    "            spec_scores.append(0.0)\n",
    "    # Return computed specificity scores\n",
    "    return spec_scores\n",
    "\n",
    "def calc_Accuracy(truth, pred, classes):\n",
    "    acc_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            gt = np.equal(truth, i)\n",
    "            pd = np.equal(pred, i)\n",
    "            not_gt = np.logical_not(np.equal(truth, i))\n",
    "            not_pd = np.logical_not(np.equal(pred, i))\n",
    "            # Calculate accuracy\n",
    "            acc = (np.logical_and(pd, gt).sum() + \\\n",
    "                   np.logical_and(not_pd, not_gt).sum()) /  gt.size\n",
    "            acc_scores.append(acc)\n",
    "        except ZeroDivisionError:\n",
    "            acc_scores.append(0.0)\n",
    "    # Return computed accuracy scores\n",
    "    return acc_scores\n",
    "\n",
    "def calc_Precision(truth, pred, classes):\n",
    "    prec_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            gt = np.equal(truth, i)\n",
    "            pd = np.equal(pred, i)\n",
    "            # Calculate precision\n",
    "            prec = np.logical_and(pd, gt).sum() / pd.sum()\n",
    "            prec_scores.append(prec)\n",
    "        except ZeroDivisionError:\n",
    "            prec_scores.append(0.0)\n",
    "    # Return computed precision scores\n",
    "    return prec_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Metric Analysis on Ground Truth vs Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Data IO Interface for NIFTI data\n",
    "## There are 3 classes due to [background, maxilla, mandible]\n",
    "structure_dict = {\"Maxillary\": 1, \"Mandible\": 2}\n",
    "data_path = \"/restricted/projectnb/ortho-ar/MinKim/predictions/teeth_redo_50\"\n",
    "interface = DICOM_interface(structure_dict = structure_dict, classes=3, annotation_tag=\"rtstruct\")\n",
    "\n",
    "# Create Data IO object to load and write samples in the file structure\n",
    "data_io = Data_IO(interface, input_path=\"predictions/teeth_predict\", output_path=\"predictions/predicted_teeth\")\n",
    "\n",
    "# Access all available samples in our file structure\n",
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "\n",
    "# Initialize dataframe\n",
    "cols = [\"index\", \"score\", \"background\", \"Maxiilary\", \"Mandible\"]\n",
    "df = pd.DataFrame(data=[], dtype=np.float64, columns=cols)\n",
    "df_roc = pd.DataFrame(data=[], dtype=np.float64, columns=cols)\n",
    "# Iterate over each sample\n",
    "for index in tqdm(sample_list):\n",
    "     # Load a sample including its image, ground truth and prediction\n",
    "     sample = data_io.sample_loader(index, load_seg=True, load_pred=True)\n",
    "     # Access image, ground truth and prediction data\n",
    "     image = sample.img_data\n",
    "     truth = sample.seg_data\n",
    "     pred = sample.pred_data\n",
    "\n",
    "     # Compute diverse Scores\n",
    "     dsc = calc_DSC(truth, pred, classes=3)\n",
    "     df = df.append(pd.Series([index, \"DSC\"] + dsc, index=cols),\n",
    "                    ignore_index=True)\n",
    "     iou = calc_IoU(truth, pred, classes=3)\n",
    "     df = df.append(pd.Series([index, \"IoU\"] + iou, index=cols),\n",
    "                    ignore_index=True)\n",
    "     sens = calc_Sensitivity(truth, pred, classes=3)\n",
    "     df = df.append(pd.Series([index, \"Sens\"] + sens, index=cols),\n",
    "                    ignore_index=True)\n",
    "     spec = calc_Specificity(truth, pred, classes=3)\n",
    "     df = df.append(pd.Series([index, \"Spec\"] + spec, index=cols),\n",
    "                    ignore_index=True)\n",
    "     prec = calc_Precision(truth, pred, classes=3)\n",
    "     df = df.append(pd.Series([index, \"Prec\"] + prec, index=cols),\n",
    "                    ignore_index=True)\n",
    "     acc = calc_Accuracy(truth, pred, classes=3)\n",
    "     df = df.append(pd.Series([index, \"Acc\"] + acc, index=cols),\n",
    "                    ignore_index=True)\n",
    "\n",
    "# Compute Visualization\n",
    "sample = data_io.sample_loader(index, load_seg=True, load_pred=True)\n",
    "#Access image, ground truth and prediction data\n",
    "image = sample.img_data\n",
    "truth = sample.seg_data\n",
    "pred = sample.pred_data\n",
    "visualize_evaluation(index, image, truth, pred, \"predictions/visualization_teeth_redo_pilot5\")\n",
    "# Output complete dataframe\n",
    "print(df)\n",
    "# Store complete dataframe to disk\n",
    "path_res_detailed = os.path.join(\"predictions/evaluation_teeth\", \"cv_results.detailed.csv\")\n",
    "df.to_csv(path_res_detailed, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
